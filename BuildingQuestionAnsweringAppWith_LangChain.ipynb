{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdYHDtl5mKHec7Qne11Cvg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/musinaa/LangChain/blob/eda/BuildingQuestionAnsweringAppWith_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Your Own GPT-Powered Applications using LangChain**"
      ],
      "metadata": {
        "id": "ZOnvhxdPSviT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step** 1 – Setting Up the Development Environment\n"
      ],
      "metadata": {
        "id": "rTFkzT8ATAFP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0LVnSSwS6tb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbdae2b-7121-4f96-b30b-dc5f0802ceaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.271-py3-none-any.whl (1.5 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.21 (from langchain)\n",
            "  Downloading langsmith-0.0.26-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.2.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, langsmith, dataclasses-json, langchain\n",
            "Successfully installed dataclasses-json-0.5.14 langchain-0.0.271 langsmith-0.0.26 marshmallow-3.20.1 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "#You can now install the LangChain library using pip:\n",
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#As we’ll be using OpenAI’s language models, we need to install the OpenAI\n",
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKf_xAD-LgSH",
        "outputId": "b1b4d0c3-4072-4c79-e513-7c8f40675eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.9-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step** **2** – Setting the OPENAI_API_KEY as an Environment Variable\n"
      ],
      "metadata": {
        "id": "NLXEaE-vTb_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Next, sign into your OpenAI account. Navigate to account settings > View API Keys. Generate a secret key and copy it\n",
        "#Set the \"OPENAI_API_KEY\" to your to the secret API key that you just copied\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "hv-l__zVLrua"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step** **3** – Simple LLM Call Using LangChain"
      ],
      "metadata": {
        "id": "k2asG99UYU09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#let’s import the OpenAI wrapper. In this example, we’ll use the text-davinci-003 model\n",
        "#“text-davinci-003: Can do any language task with better quality, longer output,\n",
        "#and consistent instruction-following than the curie, babbage, or ada models. Also supports inserting completions within text.”\n",
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")"
      ],
      "metadata": {
        "id": "PAEiggJMNWfF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's define a question string and generate a response:\n",
        "question = \"Which is the best programming language to learn in 2023?\"\n",
        "print(llm(question))"
      ],
      "metadata": {
        "id": "6Ui0mq6NNdb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb33eb88-95fd-450c-965d-792bd95005d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The best programming language to learn in 2023 will likely depend on your individual goals and interests. However, some of the most popular languages to learn in 2023 are Python, JavaScript, C#, C++, Java, and Go. These languages are all widely used in the software development industry and offer a great foundation for learning more advanced programming concepts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step** **4** – Creating a Prompt Template"
      ],
      "metadata": {
        "id": "1aALpPm5Yv2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's ask another question on the top resources to learn a new programming language, say, Golang\n",
        "question = \"What are the top 4 exporters of avocado globally?\"\n",
        "print(llm(question))"
      ],
      "metadata": {
        "id": "H3GlWH3ZNqnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08405a5e-fdf7-4428-dec6-5f7b6e39bd57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Mexico \n",
            "2. Colombia\n",
            "3. Peru \n",
            "4. Dominican Republic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We can create a simple template to get the top k resources to learn any tech stack. Here, we use the k and this  as input_variables\n",
        "from langchain import PromptTemplate\n",
        "template = \"What are the top {k} resources to learn {this} in 2023?\"\n",
        "prompt = PromptTemplate(template=template,input_variables=['k','this'])"
      ],
      "metadata": {
        "id": "UROvJnyIOA7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step** **5** – Running Our First LLM Chain\n"
      ],
      "metadata": {
        "id": "G9u5JA23ZMBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We now have an LLM and a prompt template that we can reuse across multiple LLM calls.\n",
        "llm = OpenAI(model_name=\"text-davinci-003\")\n",
        "prompt = PromptTemplate(template=template,input_variables=['k','this'])"
      ],
      "metadata": {
        "id": "frklrKC_OWV1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s go ahead and create an LLMChain:\n",
        "from langchain import LLMChain\n",
        "chain = LLMChain(llm=llm,prompt=prompt)"
      ],
      "metadata": {
        "id": "w94bUlHoOiSi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#You can now pass in the inputs as a dictionary and run the LLM chain as shown:\n",
        "input = {'k':3,'this':'Rust'}\n",
        "print(chain.run(input))"
      ],
      "metadata": {
        "id": "3yPhsD43OuPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b098f95a-8047-4f09-dfb8-c16496e4446d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Rust Programming Language Book by Steve Klabnik and Carol Nichols \n",
            "2. Official Rust Documentation \n",
            "3. Rust By Example Tutorials\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And that’s a wrap! You know how to use LangChain to build a simple Q&A app. I hope you’ve gained a cursory understanding of LangChain’s capabilities. As a next step, try exploring LangChain to build more interesting applications. Happy coding!"
      ],
      "metadata": {
        "id": "cfg7JGJjZi1x"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QIu10r-fOx_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}